{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import collections\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    if isinstance(x, collections.Iterable):\n",
    "        return [a for i in x for a in flatten(i)]\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "def strip_ideographic(text):\n",
    "    # Ideographic_Description_Characters = [\"⿰\", \"⿱\", \"⿲\", \"⿳\", \"⿴\", \"⿵\", \"⿶\", \"⿷\", \"⿸\", \"⿹\", \"⿺\", \"⿻\"]\n",
    "    Ideographic_Description_Characters = \"⿰⿱⿲⿳⿴⿵⿶⿷⿸⿹⿺⿻\"\n",
    "    translator = str.maketrans(\"\", \"\", Ideographic_Description_Characters)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def get_all_word_bukken(filename=\"IDS-UCS-Basic.txt\"):\n",
    "    bukkens = []\n",
    "    words = []  # actually chars\n",
    "    word_bukken = {}\n",
    "    for i, line in enumerate(open(filename, \"r\").readlines()):\n",
    "        if line[0] != \"U\":  # not start with U+XXXX means it is not a word\n",
    "            continue\n",
    "        line = line.split()\n",
    "        word = line[1]\n",
    "        components = line[2]\n",
    "        components = strip_ideographic(components)\n",
    "        bukken = []\n",
    "        while \";\" in components:\n",
    "            bukken.append(components[:components.find(\";\") + 1])\n",
    "            components = components[components.find(\";\") + 1:]\n",
    "        while len(components) > 1:\n",
    "            bukken.append(components[0])\n",
    "            components = components[1:]\n",
    "        bukken.append(components)\n",
    "        words.append(word)\n",
    "        word_bukken[words.index(word)] = bukken\n",
    "        if len(bukken) == 1 and bukken[0] == word:\n",
    "            bukkens.append(word)\n",
    "\n",
    "    def expand_bukken(bukken):\n",
    "        expanded_bukken = []\n",
    "        for b in bukken:\n",
    "            if b in bukkens:\n",
    "                expanded_bukken.append(bukkens.index(b))\n",
    "            else:\n",
    "                if b in words:\n",
    "                    expanded_bukken.append(expand_bukken(word_bukken[words.index(b)]))\n",
    "                else:\n",
    "                    bukkens.append(b)\n",
    "                    expanded_bukken.append(bukkens.index(b))\n",
    "        return expanded_bukken\n",
    "\n",
    "    for i_word, i_bukken in word_bukken.items():\n",
    "        b_list = expand_bukken(i_bukken)\n",
    "        b_list = flatten(b_list)\n",
    "        word_bukken[i_word] = b_list\n",
    "    return words, bukkens, word_bukken\n",
    "\n",
    "\n",
    "def get_all_character(filename=\"IDS-UCS-Basic.txt\"):\n",
    "    chars = []\n",
    "\n",
    "    for i, line in enumerate(open(filename, \"r\").readlines()):\n",
    "        if line[0] != \"U\":  # not start with U+XXXX means it is not a word\n",
    "            continue\n",
    "        line = line.split()\n",
    "        char = line[1]\n",
    "        chars.append(char)\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, bukkens, word_bukken = get_all_word_bukken(\"IDS-UCS-Basic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bukkenList_word = {}\n",
    "for word, bukkenList in word_bukken.items():\n",
    "    bukkenList=','.join(map(str,bukkenList))\n",
    "    if bukkenList not in bukkenList_word.keys():\n",
    "        bukkenList_word[bukkenList] = [word]\n",
    "    else:\n",
    "        bukkenList_word[bukkenList].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = [ws for bukkenList, ws in bukkenList_word.items() if len(ws)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['仌', '从']\n",
      "['冈', '罓']\n",
      "['勀', '勊']\n",
      "['勇', '勈']\n",
      "['另', '叻']\n",
      "['叧', '叨']\n",
      "['吅', '吕']\n",
      "['呐', '呙']\n",
      "['呗', '员']\n",
      "['咠', '咡']\n",
      "['員', '唄']\n",
      "['喦', '嵒']\n",
      "['夐', '敻']\n",
      "['娄', '籹']\n",
      "['季', '秄']\n",
      "['屺', '岂']\n",
      "['屻', '岃']\n",
      "['屾', '岀']\n",
      "['岋', '岌']\n",
      "['岑', '岒']\n",
      "['岝', '岞']\n",
      "['岧', '岹']\n",
      "['岫', '峀']\n",
      "['岭', '岺']\n",
      "['峆', '峇']\n",
      "['峈', '峉']\n",
      "['峏', '耑']\n",
      "['峒', '峝']\n",
      "['峗', '峞']\n",
      "['峛', '峢']\n",
      "['峨', '峩']\n",
      "['峯', '峰']\n",
      "['崐', '崑']\n",
      "['崒', '崪']\n",
      "['崓', '崮']\n",
      "['崕', '崖']\n",
      "['崘', '崙']\n",
      "['崛', '崫']\n",
      "['崟', '崯']\n",
      "['崠', '崬']\n",
      "['崳', '嵛']\n",
      "['嵏', '嵕']\n",
      "['嵩', '嵪']\n",
      "['嵯', '嵳']\n",
      "['嵷', '嵸']\n",
      "['嶃', '嶄']\n",
      "['嶋', '嶌']\n",
      "['嶕', '嶣']\n",
      "['嶚', '嶛']\n",
      "['嶡', '嶥']\n",
      "['嶢', '嶤']\n",
      "['嶪', '嶫']\n",
      "['巃', '巄']\n",
      "['巖', '巗']\n",
      "['巘', '巚']\n",
      "['弑', '弒']\n",
      "['悥', '訫']\n",
      "['抛', '拋']\n",
      "['抳', '抿']\n",
      "['插', '揷']\n",
      "['早', '旪']\n",
      "['旭', '旮']\n",
      "['旰', '旱']\n",
      "['旻', '旼']\n",
      "['昉', '昘']\n",
      "['昒', '易']\n",
      "['昞', '昺']\n",
      "['星', '甠']\n",
      "['晀', '晁']\n",
      "['晃', '晄']\n",
      "['晌', '晑']\n",
      "['晚', '晩']\n",
      "['晟', '晠']\n",
      "['景', '晾']\n",
      "['暈', '暉']\n",
      "['暏', '暑']\n",
      "['曄', '曅']\n",
      "['朞', '期']\n",
      "['杍', '李']\n",
      "['杠', '杢']\n",
      "['松', '枩']\n",
      "['柤', '査']\n",
      "['查', '柦']\n",
      "['柰', '标']\n",
      "['棗', '棘']\n",
      "['毗', '毘']\n",
      "['泵', '砅']\n",
      "['炅', '炚']\n",
      "['炎', '炏']\n",
      "['烘', '烡']\n",
      "['町', '甼']\n",
      "['界', '畍']\n",
      "['略', '畧']\n",
      "['窵', '鴪']\n",
      "['簑', '簔']\n",
      "['粠', '粪']\n",
      "['羣', '群']\n",
      "['翋', '翌']\n",
      "['翕', '翖']\n",
      "['蓤', '蔆']\n",
      "['郎', '郞']\n",
      "['閃', '閄']\n",
      "['雥', '雦']\n",
      "['頮', '颒']\n",
      "['鳼', '鴍']\n",
      "['鵝', '鵞']\n",
      "['鶘', '鶦']\n",
      "['鶿', '鷀']\n",
      "['鷿', '鸊']\n"
     ]
    }
   ],
   "source": [
    "for w_list in similar_words:\n",
    "    print([words[x] for x in w_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109  \"similar\" characters in totally  20902 characters in IDS-UCS-Basic.\n"
     ]
    }
   ],
   "source": [
    "print(len(similar_words), ' \"similar\" characters in totally ', len(words), 'characters in IDS-UCS-Basic.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('words_bukkens_word_bukken.pkl', 'wb') as f:\n",
    "    pickle.dump((words, bukkens, word_bukken),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch04]",
   "language": "python",
   "name": "conda-env-pytorch04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
